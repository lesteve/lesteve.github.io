
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>NiLearn: Machine learning for NeuroImaging in Python &mdash; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1a',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/copybutton.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Machine learning for NeuroImaging" href="index.html" />
    <link rel="next" title="1. Introduction" href="introduction.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections 
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}
            
	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body>
<div id="logo-banner">
  <div class="logo">
    <a href="index.html">
      <img src="_static/nilearn-logo.png" alt="NiLearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="auto_examples/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="data_analysis/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="building_blocks/haxby_searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="data_analysis/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="building_blocks/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>NiLearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="introduction.html" title="1. Introduction"
             accesskey="N">next</a> |</li>
<li><a href="index.html">NiLearn Home</a> |&nbsp;</li>
<li><a href="#">User Guide</a> |&nbsp;</li>
<li><a href="auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>
 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="AUTHORS.html#citing">citing the
                    scikit-learn</a> if you use it.</p></li>
  </ul>

  <h4>Next topic</h4>
  <p class="topless"><a href="introduction.html"
                        title="next chapter">1. Introduction</a></p>

<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="user-guide-table-of-contents">
<span id="user-guide"></span><h1>User guide: table of contents<a class="headerlink" href="#user-guide-table-of-contents" title="Permalink to this headline">Â¶</a></h1>
<style type="text/css">
  div.bodywrapper blockquote {
      margin: 0 ;
  }

  div.toctree-wrapper ul {
      margin-top: 0 ;
      margin-bottom: 0 ;
      padding-left: 10px ;
  }

  li.toctree-l1 {
      padding: 0 0 0.5em 0 ;
      list-style-type: none;
      font-size: 150% ;
      font-weight: bold;
      }

  li.toctree-l1 ul {
      padding-left: 40px ;
  }

  li.toctree-l2 {
      font-size: 75% ;
      list-style-type: square;
      font-weight: normal;
      }

  li.toctree-l3 {
      font-size: 85% ;
      list-style-type: circle;
      font-weight: normal;
      }

</style> <SCRIPT>
 //Function to make the index toctree collapsible
 $(function () {
     $('.toctree-l2')
         .click(function(event){
             if (event.target.tagName.toLowerCase() != "a") {
                 if ($(this).children('ul').length > 0) {
                      $(this).attr('data-content',
                          (!$(this).children('ul').is(':hidden')) ? '\u25ba' : '\u25bc');
                     $(this).children('ul').toggle();
                 }
                 return true; //Makes links clickable
             }
         })
         .mousedown(function(event){ return false; }) //Firefox highlighting fix
         .children('ul').hide();
     // Initialize the values
     $('li.toctree-l2:not(:has(ul))').attr('data-content', '-');
     $('li.toctree-l2:has(ul)').attr('data-content', '\u25ba');
     $('li.toctree-l2:has(ul)').css('cursor', 'pointer');

     $('.toctree-l2').hover(
         function () {
             if ($(this).children('ul').length > 0) {
                 $(this).css('background-color', '#D0D0D0').children('ul').css('background-color', '#F0F0F0');
                 $(this).attr('data-content',
                     (!$(this).children('ul').is(':hidden')) ? '\u25bc' : '\u25ba');
             }
             else {
                 $(this).css('background-color', '#F9F9F9');
             }
         },
         function () {
             $(this).css('background-color', 'white').children('ul').css('background-color', 'white');
             if ($(this).children('ul').length > 0) {
                 $(this).attr('data-content',
                     (!$(this).children('ul').is(':hidden')) ? '\u25bc' : '\u25ba');
             }
         }
     );
 });

 </SCRIPT>

<style type="text/css">
  div.bodywrapper blockquote {
      margin: 0 ;
  }

  div.toctree-wrapper ul {
      margin: 0 ;
      padding-left: 0px ;
  }

  li, ul {
      transition-duration: 0.2s;
  }

  li.toctree-l1 {
      padding: 5px 0 0;
      list-style-type: none;
      font-size: 150% ;
      font-family: Arial, sans-serif;
      background-color: #f2f2f2;
      font-weight: normal;
      color: #20435c;
      margin-left: 0;
      margin-bottom: 1.2em;
      font-weight: bold;
      }

  li.toctree-l1 a {
      padding: 0 0 0 10px ;
      color: #314F64 ;
  }

  li.toctree-l2 {
      padding: 0.25em 0 0.25em 0 ;
      list-style-type: none;
      background-color: #FFFFFF;
      font-size: 85% ;
      font-weight: normal;
  }

  li.toctree-l2 ul {
      padding-left: 40px ;
  }


  li.toctree-l2:before {
      content: attr(data-content) ;
      font-size: 85% ;
      color: #777 ;
      display: inline-block;
      width: 10px;
  }

  li.toctree-l3 {
      font-size: 88% ;
      list-style-type: square;
      font-weight: normal;
  }

  li.toctree-l4 {
      font-size: 93% ;
      list-style-type: circle;
      font-weight: normal;
  }

  div.topic li.toctree-l1 {
      font-size: 100% ;
      font-weight: bold;
      background-color: transparent;
      margin-bottom: 0;
      margin-left: 1.5em;
      display:inline;
  }

  div.topic p {
      font-size: 90% ;
      margin: 0.4ex;
  }

  div.topic p.topic-title {
      display:inline;
      font-size: 100% ;
      margin-bottom: 0;
  }

  div.sidebar {
      width: 25ex ;
  }

</style><div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#machine-learning-in-neuroimaging-what-and-why">1.1. Machine Learning in NeuroImaging: what and why</a><ul>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#machine-learning-problems-and-vocabulary">1.1.1. Machine learning problems and vocabulary</a></li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#why-is-machine-learning-relevant-to-neuroimaging-a-few-examples">1.1.2. Why is machine learning relevant to NeuroImaging: a few examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#installation">1.2. Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#installing-the-environment">1.2.1. Installing the environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#python-scientific-stack">1.2.1.1. Python scientific stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#nibabel-reading-neuroimaging-files">1.2.1.2. Nibabel: reading neuroimaging files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#installing-nilearn">1.2.2. Installing nilearn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#downloading-the-development-version">1.2.2.1. Downloading the development version</a></li>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#setting-up">1.2.2.2. Setting up</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#python-for-neuroimaging-a-quick-start">1.3. Python for NeuroImaging: a quick-start</a><ul>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#scientific-computing-with-python">1.3.1. Scientific computing with Python</a><ul>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#basic-numerics">1.3.1.1. Basic numerics</a></li>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#scikit-learn-machine-learning-in-python">1.3.1.2. Scikit-learn: machine learning in Python</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#finding-help">1.3.2. Finding help</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_analysis/index.html">2. NeuroImaging data analysis pipelines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="data_analysis/decoding.html">2.1. Decoding: predicting behavior or phenotype from brain images</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/decoding.html#data-loading-and-preparation">2.1.1. Data loading and preparation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#the-haxby-2001-experiment">2.1.1.1. The Haxby 2001 experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#loading-the-data-into-python">2.1.1.2. Loading the data into Python</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/decoding.html#performing-the-decoding-analysis">2.1.2. Performing the decoding analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#the-prediction-engine">2.1.2.1. The prediction engine</a><ul>
<li class="toctree-l5"><a class="reference internal" href="data_analysis/decoding.html#an-estimator-object">2.1.2.1.1. An estimator object</a></li>
<li class="toctree-l5"><a class="reference internal" href="data_analysis/decoding.html#applying-it-to-data-fit-train-and-predict-test">2.1.2.1.2. Applying it to data: fit (train) and predict (test)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#measuring-prediction-performance">2.1.2.2. Measuring prediction performance</a><ul>
<li class="toctree-l5"><a class="reference internal" href="data_analysis/decoding.html#cross-validation">2.1.2.2.1. Cross-validation</a></li>
<li class="toctree-l5"><a class="reference internal" href="data_analysis/decoding.html#choosing-a-good-cross-validation-strategy">2.1.2.2.2. Choosing a good cross-validation strategy</a></li>
<li class="toctree-l5"><a class="reference internal" href="data_analysis/decoding.html#choice-of-the-prediction-accuracy-measure">2.1.2.2.3. Choice of the prediction accuracy measure</a></li>
<li class="toctree-l5"><a class="reference internal" href="data_analysis/decoding.html#measuring-the-chance-level">2.1.2.2.4. Measuring the chance level</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#visualizing-the-decoder-s-weights">2.1.2.3. Visualizing the decoder&#8217;s weights</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/decoding.html#decoding-without-a-mask-anova-svm">2.1.3. Decoding without a mask: Anova-SVM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#dimension-reduction-with-feature-selection">2.1.3.1. Dimension reduction with feature selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#visualizing-the-results">2.1.3.2. Visualizing the results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/decoding.html#going-further-with-scikit-learn">2.1.4. Going further with scikit-learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#changing-the-prediction-engine">2.1.4.1. Changing the prediction engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/decoding.html#changing-the-feature-selection">2.1.4.2. Changing the feature selection</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data_analysis/parcellating.html">2.2. Parcellating the brain in regions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/parcellating.html#a-resting-state-dataset">2.2.1. A resting-state dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/parcellating.html#preprocessing-loading-and-masking">2.2.2. Preprocessing: loading and masking</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/parcellating.html#applying-ward-clustering">2.2.3. Applying Ward clustering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/parcellating.html#running-the-ward-algorithm">2.2.3.1. Running the Ward algorithm</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/parcellating.html#post-processing-and-visualizing-the-parcels">2.2.4. Post-Processing and visualizing the parcels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/parcellating.html#unmasking">2.2.4.1. Unmasking</a></li>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/parcellating.html#label-visualization">2.2.4.2. Label visualization</a></li>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/parcellating.html#compressed-picture">2.2.4.3. Compressed picture</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data_analysis/resting_state_networks.html">2.3. Extracting resting-state networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/resting_state_networks.html#data-preparation">2.3.1. Data preparation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/resting_state_networks.html#retrieving-example-data">2.3.1.1. Retrieving example data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/resting_state_networks.html#applying-canica">2.3.2. Applying CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/resting_state_networks.html#visualizing-the-results">2.3.3. Visualizing the results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data_analysis/functional_connectomes.html">2.4. Learning functional connectomes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/functional_connectomes.html#sparse-inverse-covariance-for-functional-connectomes">2.4.1. Sparse inverse covariance for functional connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/functional_connectomes.html#testing-the-different-approaches-on-simulated-data">2.4.2. Testing the different approaches on simulated data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/functional_connectomes.html#synthetic-signals">2.4.2.1. Synthetic signals</a></li>
<li class="toctree-l4"><a class="reference internal" href="data_analysis/functional_connectomes.html#estimation">2.4.2.2. Estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="data_analysis/functional_connectomes.html#a-real-data-example">2.4.3. A real-data example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="building_blocks/index.html">3. The nilearn building blocks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/pipeline_introduction.html">3.1. Introduction to the neuroimaging machine-learning pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/pipeline_introduction.html#data-loading-and-preprocessing">3.1.1. Data loading and preprocessing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/pipeline_introduction.html#downloading-the-data">3.1.1.1. Downloading the data</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/pipeline_introduction.html#loading-non-image-data-experiment-description">3.1.1.2. Loading non image data: experiment description</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/pipeline_introduction.html#masking-the-data-from-4d-image-to-2d-array">3.1.1.3. Masking the data: from 4D image to 2D array</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/pipeline_introduction.html#applying-a-mask">3.1.1.3.1. Applying a mask</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/pipeline_introduction.html#automatically-computing-a-mask">3.1.1.3.2. Automatically computing a mask</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/pipeline_introduction.html#applying-a-scikit-learn-machine-learning-method">3.1.2. Applying a scikit-learn machine learning method</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/pipeline_introduction.html#unmasking-inverse-transform">3.1.3. Unmasking (inverse_transform)</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/pipeline_introduction.html#visualizing-results">3.1.4. Visualizing results</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/pipeline_introduction.html#going-further">3.1.5. Going further</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/data_preparation.html">3.2. Data preparation: input/output and basic transformation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/data_preparation.html#niftimasker-loading-masking-and-filtering">3.2.1. <tt class="docutils literal"><span class="pre">NiftiMasker</span></tt>: loading, masking and filtering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/data_preparation.html#custom-data-loading">3.2.1.1. Custom data loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/data_preparation.html#controlling-how-the-mask-is-computed-from-the-data">3.2.1.2. Controlling how the mask is computed from the data</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/data_preparation.html#computing-the-mask">3.2.1.2.1. Computing the mask</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/data_preparation.html#common-data-preparation-steps-resampling-smoothing-filtering">3.2.1.3. Common data preparation steps: resampling, smoothing, filtering</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/data_preparation.html#resampling">3.2.1.3.1. Resampling</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/data_preparation.html#smoothing">3.2.1.3.2. Smoothing</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/data_preparation.html#temporal-filtering">3.2.1.3.3. Temporal Filtering</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/data_preparation.html#inverse-transform-unmasking-data">3.2.1.4. Inverse transform: unmasking data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/data_preparation.html#extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker">3.2.2. Extraction of signals from regions: <tt class="docutils literal"><span class="pre">NiftiLabelsMasker</span></tt>, <tt class="docutils literal"><span class="pre">NiftiMapsMasker</span></tt>.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/data_preparation.html#regions-definition">3.2.2.1. Regions definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/data_preparation.html#niftimapsmasker-usage">3.2.2.2. <tt class="docutils literal"><span class="pre">NiftiMapsMasker</span></tt> Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/data_preparation.html#niftilabelsmasker-usage">3.2.2.3. <tt class="docutils literal"><span class="pre">NiftiLabelsMasker</span></tt> Usage</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/supervised_learning.html">3.3. Supervised learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/estimator_choice.html">3.3.1. Considerations on the choice of an estimator</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/estimator_choice.html#predictions-regression-classification-and-multi-class">3.3.1.1. Predictions: regression, classification and multi-class</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/estimator_choice.html#regression">3.3.1.1.1. Regression</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/estimator_choice.html#classification-two-classes-or-multi-class">3.3.1.1.2. Classification: two classes or multi-class</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/estimator_choice.html#setting-estimator-parameters">3.3.1.2. Setting estimator parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/estimator_choice.html#different-linear-models">3.3.1.3. Different linear models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/searchlight.html">3.3.2. Searchlight : finding voxels containing information</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/searchlight.html#principle-of-the-searchlight">3.3.2.1. Principle of the Searchlight</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/searchlight.html#preparing-the-data">3.3.2.2. Preparing the data</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/searchlight.html#loading">3.3.2.2.1. Loading</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/searchlight.html#reshaping-the-data">3.3.2.2.2. Reshaping the data</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/searchlight.html#masking">3.3.2.2.3. Masking</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/searchlight.html#third-step-setting-up-the-searchlight">3.3.2.3. Third Step: Setting up the searchlight</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/searchlight.html#classifier">3.3.2.3.1. Classifier</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/searchlight.html#score-function">3.3.2.3.2. Score function</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/searchlight.html#cross-validation">3.3.2.3.3. Cross validation</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/searchlight.html#running-searchlight">3.3.2.4. Running Searchlight</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/searchlight.html#visualization">3.3.2.5. Visualization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/searchlight.html#id1">3.3.2.5.1. Searchlight</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/searchlight.html#comparing-to-massively-univariate-analysis-f-score-or-spm">3.3.2.5.2. Comparing to massively univariate analysis: F_score or SPM</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/decoding_simulated.html">3.3.3. Decoding on simulated data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/decoding_simulated.html#simple-neuroimaging-like-simulations">3.3.3.1. Simple NeuroImaging-like simulations</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/decoding_simulated.html#running-various-estimators">3.3.3.2. Running various estimators</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/unsupervised_learning.html">3.4. Unsupervised learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/ica.html">3.4.1. ICA on resting-state data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/ica.html#data-preparation">3.4.1.1. Data preparation</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/ica.html#retrieving-the-example-data">3.4.1.1.1. Retrieving the example data</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/ica.html#concatenating-smoothing-and-masking">3.4.1.1.2. Concatenating, smoothing, and masking</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/ica.html#applying-ica">3.4.1.2. Applying ICA</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/ica.html#visualizing-the-results">3.4.1.3. Visualizing the results</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/plotting.html">3.5. Plotting brain images</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/plotting.html#different-plotting-functions">3.5.1. Different plotting functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/plotting.html#different-display-modes">3.5.2. Different display modes</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/plotting.html#adding-overlays-edges-and-contours">3.5.3. Adding overlays, edges and contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/plotting.html#saving-to-an-image-file">3.5.4. Saving to an image file</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/manipulating_mr_images.html">3.6. MRI data manipulation: input/output, masking, ROIs, smoothing...</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#loading-data">3.6.1. Loading data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#fetching-datasets">3.6.1.1. Fetching datasets</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/generated/nilearn.datasets.fetch_haxby.html">3.6.1.1.1. nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/generated/nilearn.datasets.fetch_haxby_simple.html">3.6.1.1.2. nilearn.datasets.fetch_haxby_simple</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/generated/nilearn.datasets.fetch_nyu_rest.html">3.6.1.1.3. nilearn.datasets.fetch_nyu_rest</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/generated/nilearn.datasets.fetch_adhd.html">3.6.1.1.4. nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/generated/nilearn.datasets.fetch_miyawaki2008.html">3.6.1.1.5. nilearn.datasets.fetch_miyawaki2008</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#loading-your-own-data">3.6.1.2. Loading your own data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#understanding-neuroimaging-data">3.6.2. Understanding Neuroimaging data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#nifti-and-analyze-files">3.6.2.1. Nifti and Analyze files</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#niimg-like-objects">3.6.2.2. Niimg-like objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#text-files-phenotype-or-behavior">3.6.2.3. Text files: phenotype or behavior</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#masking-data-manually">3.6.3. Masking data manually</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#extracting-a-brain-mask">3.6.3.1. Extracting a brain mask</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/generated/nilearn.masking.compute_epi_mask.html">3.6.3.1.1. nilearn.masking.compute_epi_mask</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#from-4d-to-2d-arrays">3.6.3.2. From 4D to 2D arrays</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#functions-for-data-preparation-steps">3.6.4. Functions for data preparation steps</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#image-operations-creating-a-roi-mask-manually">3.6.5. Image operations: creating a ROI mask manually</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#smoothing">3.6.5.1. Smoothing</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#selecting-features">3.6.5.2. Selecting features</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#thresholding">3.6.5.3. Thresholding</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#mask-intersection">3.6.5.4. Mask intersection</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#mask-dilation">3.6.5.5. Mask dilation</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#extracting-connected-components">3.6.5.6. Extracting connected components</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manipulating_mr_images.html#saving-the-result">3.6.5.7. Saving the result</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules/reference.html">4. Reference documentation: all nilearn functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.datasets">4.1. <tt class="docutils literal"><span class="pre">nilearn.datasets</span></tt>: Automatic Dataset Fetching</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_adhd.html">4.1.1. nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_craddock_2011_atlas.html">4.1.2. nilearn.datasets.fetch_craddock_2011_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_haxby.html">4.1.3. nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_haxby_simple.html">4.1.4. nilearn.datasets.fetch_haxby_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_nyu_rest.html">4.1.5. nilearn.datasets.fetch_nyu_rest</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_icbm152_2009.html">4.1.6. nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_msdl_atlas.html">4.1.7. nilearn.datasets.fetch_msdl_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_yeo_2011_atlas.html">4.1.8. nilearn.datasets.fetch_yeo_2011_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_harvard_oxford.html">4.1.9. nilearn.datasets.load_harvard_oxford</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.decoding">4.2. <tt class="docutils literal"><span class="pre">nilearn.decoding</span></tt>: Decoding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decoding.SearchLight.html">4.2.1. nilearn.decoding.SearchLight</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.decomposition">4.3. <tt class="docutils literal"><span class="pre">nilearn.decompositon</span></tt>: Multivariate decompositions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decomposition.CanICA.html">4.3.1. nilearn.decomposition.CanICA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.image">4.4. <tt class="docutils literal"><span class="pre">nilearn.image</span></tt>: Image processing and resampling utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.high_variance_confounds.html">4.4.1. nilearn.image.high_variance_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.smooth_img.html">4.4.2. nilearn.image.smooth_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.resample_img.html">4.4.3. nilearn.image.resample_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.reorder_img.html">4.4.4. nilearn.image.reorder_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.crop_img.html">4.4.5. nilearn.image.crop_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.mean_img.html">4.4.6. nilearn.image.mean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.swap_img_hemispheres.html">4.4.7. nilearn.image.swap_img_hemispheres</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.input_data">4.5. <tt class="docutils literal"><span class="pre">nilearn.input_data</span></tt>: Loading and Processing files easily</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.input_data.NiftiMasker.html">4.5.1. nilearn.input_data.NiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.input_data.MultiNiftiMasker.html">4.5.2. nilearn.input_data.MultiNiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.input_data.NiftiLabelsMasker.html">4.5.3. nilearn.input_data.NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.input_data.NiftiMapsMasker.html">4.5.4. nilearn.input_data.NiftiMapsMasker</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.masking">4.6. <tt class="docutils literal"><span class="pre">nilearn.masking</span></tt>: Data Masking Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.region.img_to_signals_labels.html">4.6.1. nilearn.region.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.region.signals_to_img_labels.html">4.6.2. nilearn.region.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.region.img_to_signals_maps.html">4.6.3. nilearn.region.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.region.signals_to_img_maps.html">4.6.4. nilearn.region.signals_to_img_maps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.mass_univariate">4.7. <tt class="docutils literal"><span class="pre">nilearn.mass_univariate</span></tt>: Mass-univariate analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.mass_univariate.permuted_ols.html">4.7.1. nilearn.mass_univariate.permuted_ols</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.plotting">4.8. <tt class="docutils literal"><span class="pre">nilearn.plotting</span></tt>: Plotting brain data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_anat.html">4.8.1. nilearn.plotting.plot_anat</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_img.html">4.8.2. nilearn.plotting.plot_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_epi.html">4.8.3. nilearn.plotting.plot_epi</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_roi.html">4.8.4. nilearn.plotting.plot_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_stat_map.html">4.8.5. nilearn.plotting.plot_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.find_xyz_cut_coords.html">4.8.6. nilearn.plotting.find_xyz_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.slicers.OrthoSlicer.html">4.8.7. nilearn.plotting.slicers.OrthoSlicer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.signal">4.9. <tt class="docutils literal"><span class="pre">nilearn.signal</span></tt>: Preprocessing Time Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.signal.clean.html">4.9.1. nilearn.signal.clean</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="introduction.html" title="1. Introduction"
             >next</a> |</li>
<li><a href="index.html">NiLearn Home</a> |&nbsp;</li>
<li><a href="#">User Guide</a> |&nbsp;</li>
<li><a href="auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>
 
      </ul>
    </div>
    <div class="footer">
            &copy; INRIA Parietal 2010-2013.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.3.
        <span style="padding-left: 5ex;">
          <a href="_sources/user_guide.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>